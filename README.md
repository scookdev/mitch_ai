<div align="center">
  <img src="mitch-ai-logo.svg" alt="MitchAI" width="500">
</div>

# MitchAI

## AI-Powered Code Review Assistant

<!-- [![Gem Version](https://badge.fury.io/rb/mitch_ai.svg)](https://badge.fury.io/rb/mitch_ai) -->
<!-- [![Ruby CI](https://github.com/scookdev/mitch_ai/actions/workflows/ruby.yml/badge.svg)](https://github.com/scookdev/mitch_ai/actions) -->
<!-- [![Code Coverage](https://codecov.io/gh/scookdev/mitch_ai/branch/main/graph/badge.svg)](https://codecov.io/gh/scookdev/mitch_ai) -->
<!-- [![Ruby Style Guide](https://img.shields.io/badge/code_style-rubocop-brightgreen.svg)](https://github.com/rubocop/rubocop) -->

## ğŸš€ Overview

MitchAI is an intelligent CLI tool that leverages **100% local AI models** to provide comprehensive code reviews. No cloud APIs, no data sharing - your code never leaves your machine while getting professional-grade AI analysis.

## âœ¨ Features

- ğŸ  **100% Local AI** - No cloud APIs, complete privacy
- ğŸš€ **Tiered Model System** - Fast setup to premium quality
- ğŸ” **Smart Project Analysis** - Understands your codebase structure
- ğŸ¤– **Multi-language Support** - Ruby, Python, TypeScript, JavaScript, Go, Rust, Java, C++, CSS, HTML
- ğŸ›¡ï¸ **Security & Bug Detection** - Catches vulnerabilities and potential issues
- âš¡ **Lightning Fast Setup** - Get started in under 2 minutes
- ğŸ“ˆ **Quality Upgrade Path** - Improve analysis quality on demand
- ğŸ¯ **Context-Aware Reviews** - Language-specific best practices and patterns

## ğŸ› ï¸ Installation

```bash
gem install mitch-ai
```

## ğŸš€ Quick Start

```bash
# 1. Install
gem install mitch-ai

# 2. Setup (choose your performance tier)
mitch-ai setup

# 3. Review your code
mitch-ai review
```

> **ğŸ’¡ First-time setup**: MitchAI will guide you through selecting a model tier. The Fast tier gets you started in under 2 minutes!

## ğŸ’¡ Usage

### Basic Commands
```bash
# Review current directory
mitch-ai review

# Review specific file
mitch-ai review ./app/models/user.rb

# Review entire project with verbose output
mitch-ai review ./my-project -v
```

### Model Management
```bash
# See available model tiers
mitch-ai models tiers

# List installed models
mitch-ai models list

# Upgrade to better models for current project
mitch-ai models upgrade

# Install specific model
mitch-ai models install codegemma:2b
```

### Server Management
```bash
# Start MCP server for enhanced analysis
mitch-ai server start

# Check server status
mitch-ai server status

# Stop server
mitch-ai server stop
```

## ğŸ¯ Model Tiers

Choose the right balance of speed vs. quality for your needs:

### ğŸš€ Fast Tier (1.6-2.2GB)
- **Setup time**: ~2 minutes
- **Models**: `codegemma:2b`, `phi3:mini`
- **Best for**: Quick reviews, immediate feedback
- **Quality**: â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜†â˜†â˜† (7/10)

### âš–ï¸ Balanced Tier (3.8-4.1GB)
- **Setup time**: ~5-10 minutes  
- **Models**: `deepseek-coder:6.7b`, `qwen2.5-coder:7b`
- **Best for**: Professional development, CI/CD
- **Quality**: â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜† (9/10)

### ğŸ¯ Premium Tier (7-19GB)
- **Setup time**: ~10-15 minutes
- **Models**: `codellama:13b`, `deepseek-coder:33b`
- **Best for**: Enterprise codebases, critical reviews
- **Quality**: â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜… (10/10)

## ğŸ¤ Contributing

Contributions are welcome! Please check out [Contributing Guidelines](CONTRIBUTING.md).

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“‹ Requirements

- Ruby 3.0+
- [Ollama](https://ollama.ai/) (auto-installed during setup)

## ğŸ§ª Development

```bash
# Clone the repository
git clone https://github.com/scookdev/mitch_ai.git

# Install dependencies
bundle install

# Setup development environment (installs Ollama, downloads test models)
rake mitch_ai:setup

# Run tests
bundle exec rspec

# Run linter
bundle exec rubocop

# Start MCP server for testing
mitch-ai server start

# Test with different model tiers
mitch-ai models tiers
mitch-ai models list
```

## ğŸ—ï¸ Architecture

MitchAI uses a modular architecture combining:

- **Local AI Models** via [Ollama](https://ollama.ai/) for zero-cost, private analysis
- **Model Context Protocol (MCP)** for advanced project structure analysis
- **Tiered Model System** for flexible performance/quality trade-offs
- **Graceful Fallbacks** ensuring reliability without external dependencies

## ğŸ†š Why Choose MitchAI v1.0?

| Feature | MitchAI v1.0 | Traditional Tools |
|---------|--------------|-------------------|
| **Privacy** | ğŸ”’ 100% Local | â˜ï¸ Cloud-dependent |
| **Cost** | ğŸ†“ Completely Free | ğŸ’³ Pay-per-use APIs |
| **Setup Time** | âš¡ 2 minutes (Fast tier) | ğŸŒ Complex configuration |
| **Offline Work** | âœ… Full functionality | âŒ Internet required |
| **Data Security** | ğŸ›¡ï¸ Never leaves machine | ğŸ“¡ Sent to external servers |
| **Quality Scaling** | ğŸ“ˆ Tier-based upgrades | ğŸ”§ One-size-fits-all |

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](./LICENSE.txt)
file for details.

## ğŸ™Œ Acknowledgments

- Powered by local AI models via [Ollama](https://ollama.ai/)
- Model Context Protocol (MCP) for advanced code analysis
- Inspired by the need for private, intelligent code reviews

## ğŸ’¬ Support

If you encounter any problems or have suggestions, please [open an issue](https://github.com/scookdev/mitch_ai/issues).
